{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤— HuggingFace Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo demonstrates an end-to-end pipeline of HuggingFace transformer with MLRun.\n",
    "\n",
    "The following example demonstrates how to package a project and how to run an automatic pipeline to train, evaluate, optimize and serve an HuggingFace model using MLRun functions.\n",
    "\n",
    "1. [Register functions](#1.-Register-the-training-and-serving-functions)\n",
    "2. [Set the workflow](#2.-Setting-the-workflow)\n",
    "3. [Run the pipeline](#3.-Run-the-pipeline)\n",
    "4. [Test the pipeline](#4.-Test-the-pipeline)\n",
    "5. [gradio front-end](#5.-gradio-front-end)\n",
    "\n",
    "The pipeline consists of the following steps:\n",
    "1. **Dataset preparation** - Includes Loading data from the HuggingFace hub and applying tokenization (both train and test datasets).\n",
    "2. **Train** - Loading a model from the hub, train and evaluation.\n",
    "3. **Optimize** - Optimize the model with ONNX\n",
    "4. **Serve** - Deploy a serving function with preprocess and postprocess functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-10-27 14:05:38,684 [warning] Failed resolving version info. Ignoring and using defaults\n",
      "> 2022-10-27 14:05:41,778 [warning] Server or client version is unstable. Assuming compatible: {'server_version': '1.2.0-rc7', 'client_version': '0.0.0+unstable'}\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-10-27 14:05:41,843 [info] loaded project huggingface from MLRun DB\n"
     ]
    }
   ],
   "source": [
    "project = mlrun.get_or_create_project('huggingface', './', user_project=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Register the training functions\n",
    "We'll use our training, evaluation and serving functions. To get them, we set them into the project using project.set_function and specify additional parameters such as the container image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7f8dae47b910>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get our train functions:\n",
    "project.set_function(\n",
    "    \"src/training_pipeline.py\",\n",
    "    name=\"training\",\n",
    "    kind=\"job\",\n",
    "    image=\"yonishelach/ml-models:huggingface-demo-3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see the pipeline [functions](./src/training_pipeline.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.serving.ServingRuntime at 0x7f8daeebde50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get our ONNX serving function:\n",
    "project.set_function(\n",
    "    \"src/onnx_model_server.py\",\n",
    "    name=\"serving\", \n",
    "    kind=\"serving\", \n",
    "    image=\"yonishelach/ml-models:huggingface-demo-3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to take this project with the functions we set and the workflow we saved over to a different environemnt, first set the workflow to the project. The workflow can be set using `project.set_workflow`. After setting it, we will save the project by calling project.save. When loaded, it can be run from another environment from both code and from cli. For more information regarding saving and loading a MLRun project, see the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.projects.project.MlrunProject at 0x7f8defcfdf50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register the workflow file:\n",
    "workflow_name = \"sentiment_analysis_workflow\"\n",
    "project.set_workflow(workflow_name, \"src/workflow.py\")\n",
    "\n",
    "# Save the project:\n",
    "project.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can immediately run the project, or save it to a git repository and load/run it on another cluster or CI/CD workflow. In order to load the project from a git you should run the following command (read more about projects and CI/CD):\n",
    "```python\n",
    "project = mlrun.load_project(context=\"./\", url=\"git://github.com/<org>/<project>.git\")\n",
    "or use the CLI command:\n",
    "\n",
    "mlrun project -u \"git://github.com/mlrun/project-demo.git\" ./\n",
    "```\n",
    "We will run the pipeline using project.run with the workflow name we used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>Pipeline running (id=221975e2-7102-4d4b-b088-17ae7d17da6d), <a href=\"https://dashboard.default-tenant.app.yh43.iguazio-cd1.com/mlprojects/huggingface-yonatans/jobs/monitor-workflows/workflow/221975e2-7102-4d4b-b088-17ae7d17da6d\" target=\"_blank\"><b>click here</b></a> to view the details in MLRun UI</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: kfp Pages: 1 -->\n",
       "<svg width=\"150pt\" height=\"260pt\"\n",
       " viewBox=\"0.00 0.00 149.69 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n",
       "<title>kfp</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-256 145.6874,-256 145.6874,4 -4,4\"/>\n",
       "<!-- sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;2300440809 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;2300440809</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"131.8437,-36 13.8437,-36 9.8437,-32 9.8437,0 127.8437,0 131.8437,-4 131.8437,-36\"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"127.8437,-32 9.8437,-32 \"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"127.8437,-32 127.8437,0 \"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"127.8437,-32 131.8437,-36 \"/>\n",
       "<text text-anchor=\"middle\" x=\"70.8437\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">deploy&#45;serving</text>\n",
       "</g>\n",
       "<!-- sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;4043166129 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;4043166129</title>\n",
       "<ellipse fill=\"#00ff00\" stroke=\"#000000\" cx=\"70.8437\" cy=\"-234\" rx=\"70.6878\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"70.8437\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">prepare&#45;data</text>\n",
       "</g>\n",
       "<!-- sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;580717093 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;580717093</title>\n",
       "<ellipse fill=\"#00ff00\" stroke=\"#000000\" cx=\"70.8437\" cy=\"-162\" rx=\"48.1917\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"70.8437\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">training</text>\n",
       "</g>\n",
       "<!-- sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;4043166129&#45;&gt;sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;580717093 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;4043166129&#45;&gt;sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;580717093</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M70.8437,-215.8314C70.8437,-208.131 70.8437,-198.9743 70.8437,-190.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"74.3438,-190.4132 70.8437,-180.4133 67.3438,-190.4133 74.3438,-190.4132\"/>\n",
       "</g>\n",
       "<!-- sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;606657042 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;606657042</title>\n",
       "<ellipse fill=\"#00ff00\" stroke=\"#000000\" cx=\"70.8437\" cy=\"-90\" rx=\"68.7879\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"70.8437\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">optimization</text>\n",
       "</g>\n",
       "<!-- sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;580717093&#45;&gt;sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;606657042 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;580717093&#45;&gt;sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;606657042</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M70.8437,-143.8314C70.8437,-136.131 70.8437,-126.9743 70.8437,-118.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"74.3438,-118.4132 70.8437,-108.4133 67.3438,-118.4133 74.3438,-118.4132\"/>\n",
       "</g>\n",
       "<!-- sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;606657042&#45;&gt;sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;2300440809 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;606657042&#45;&gt;sentiment&#45;analysis&#45;pipeline&#45;f4x4x&#45;2300440809</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M70.8437,-71.8314C70.8437,-64.131 70.8437,-54.9743 70.8437,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"74.3438,-46.4132 70.8437,-36.4133 67.3438,-46.4133 74.3438,-46.4132\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f8def870c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "workflow_run = project.run(\n",
    "    name=workflow_name,\n",
    "    arguments={\n",
    "        \"dataset_name\": \"Shayanvsf/US_Airline_Sentiment\",\n",
    "        \"pretrained_tokenizer\": \"distilbert-base-uncased\",\n",
    "        \"pretrained_model\": \"distilbert-base-uncased\",\n",
    "    },\n",
    "    watch=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_function = project.get_function(\"serving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-10-27 14:51:44,124 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-huggingface-yonatans-serving.default-tenant.svc.cluster.local:8080/predict'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The sentiment is POSITIVE', 'The prediction score is 2.63582181930542']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_function.invoke(path='/predict', body='I love flying!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. gradio front-end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are taking the URL of the serving function and connecting it to the gradio code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_url = f'http://{serving_function.status.address}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://4a9ced1c19b3dcd3.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4a9ced1c19b3dcd3.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7f8da33cbf90>,\n",
       " 'http://127.0.0.1:7862/',\n",
       " 'https://4a9ced1c19b3dcd3.gradio.app')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentiment(text):\n",
    "    resp = requests.post(serving_url, json={\"text\": text})\n",
    "    return resp.json()\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    input_box = [gr.Textbox(label=\"Text to analyze\", placeholder=\"Please insert text\")]\n",
    "    output = [gr.Textbox(label=\"Sentiment analysis result\"), gr.Textbox(label=\"Sentiment analysis score\")]\n",
    "    greet_btn = gr.Button(\"Submit\")\n",
    "    greet_btn.click(fn=sentiment, inputs=input_box, outputs=output)\n",
    "\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
