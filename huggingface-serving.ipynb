{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building application + model serving pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-10-27 13:19:41,154 [warning] Failed resolving version info. Ignoring and using defaults\n",
      "> 2022-10-27 13:19:44,288 [warning] Server or client version is unstable. Assuming compatible: {'server_version': '1.2.0-rc7', 'client_version': '0.0.0+unstable'}\n"
     ]
    }
   ],
   "source": [
    "import mlrun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-10-27 13:20:15,984 [info] loaded project huggingface from None or context and saved in MLRun DB\n"
     ]
    }
   ],
   "source": [
    "project = mlrun.get_or_create_project('huggingface', context='./', user_project=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a serving function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The serving function is consisted of preprocess functions that transfers the text input into a request for the serving function, and the postprocess function passes the model output into the gradio interface. \n",
    "\n",
    "See the functions in [here](./src/serving.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_function = mlrun.code_to_function(\n",
    "    filename=\"src/serving.py\",\n",
    "    name=\"hugging-face-serving\",\n",
    "    kind=\"serving\", \n",
    "    image=\"yonishelach/ml-models:huggingface-demo-3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our serving graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the serving graph topology with the step order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the topology and get the graph object:\n",
    "graph = serving_function.set_topology(\"flow\", engine=\"async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: mlrun&#45;flow Pages: 1 -->\n",
       "<svg width=\"642pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 641.56 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>mlrun&#45;flow</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-40 637.5587,-40 637.5587,4 -4,4\"/>\n",
       "<!-- _start -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>_start</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"38.5476,-.0493 40.698,-.1479 42.8263,-.2953 44.9236,-.4913 46.9815,-.7353 48.9917,-1.0266 50.9463,-1.3645 52.8377,-1.7479 54.6587,-2.1759 56.4025,-2.6472 58.0628,-3.1606 59.634,-3.7147 61.1107,-4.308 62.4882,-4.9388 63.7625,-5.6054 64.9302,-6.3059 65.9882,-7.0385 66.9343,-7.8012 67.7669,-8.5918 68.4849,-9.4082 69.0878,-10.2481 69.5758,-11.1093 69.9496,-11.9894 70.2102,-12.886 70.3595,-13.7965 70.3997,-14.7186 70.3334,-15.6497 70.1636,-16.5873 69.8937,-17.5287 69.5276,-18.4713 69.0691,-19.4127 68.5225,-20.3503 67.8923,-21.2814 67.1831,-22.2035 66.3996,-23.114 65.5464,-24.0106 64.6285,-24.8907 63.6504,-25.7519 62.617,-26.5918 61.5329,-27.4082 60.4024,-28.1988 59.2299,-28.9615 58.0197,-29.6941 56.7755,-30.3946 55.5012,-31.0612 54.2002,-31.692 52.8757,-32.2853 51.5309,-32.8394 50.1684,-33.3528 48.7908,-33.8241 47.4003,-34.2521 45.9989,-34.6355 44.5886,-34.9734 43.1708,-35.2647 41.7472,-35.5087 40.3189,-35.7047 38.8872,-35.8521 37.4531,-35.9507 36.0175,-36 34.5815,-36 33.146,-35.9507 31.7119,-35.8521 30.2801,-35.7047 28.8519,-35.5087 27.4282,-35.2647 26.0105,-34.9734 24.6001,-34.6355 23.1988,-34.2521 21.8083,-33.8241 20.4306,-33.3528 19.0681,-32.8394 17.7233,-32.2853 16.3989,-31.692 15.0979,-31.0612 13.8236,-30.3946 12.5794,-29.6941 11.3691,-28.9615 10.1967,-28.1988 9.0662,-27.4082 7.982,-26.5918 6.9486,-25.7519 5.9706,-24.8907 5.0526,-24.0106 4.1995,-23.114 3.4159,-22.2035 2.7067,-21.2814 2.0765,-20.3503 1.53,-19.4127 1.0715,-18.4713 .7053,-17.5287 .4355,-16.5873 .2657,-15.6497 .1993,-14.7186 .2395,-13.7965 .3888,-12.886 .6495,-11.9894 1.0232,-11.1093 1.5112,-10.2481 2.1141,-9.4082 2.8321,-8.5918 3.6647,-7.8012 4.6109,-7.0385 5.6689,-6.3059 6.8365,-5.6054 8.1108,-4.9388 9.4884,-4.308 10.9651,-3.7147 12.5362,-3.1606 14.1966,-2.6472 15.9404,-2.1759 17.7614,-1.7479 19.6528,-1.3645 21.6074,-1.0266 23.6176,-.7353 25.6755,-.4913 27.7728,-.2953 29.901,-.1479 32.0515,-.0493 34.2154,0 36.3837,0 38.5476,-.0493\"/>\n",
       "<text text-anchor=\"middle\" x=\"35.2995\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">start</text>\n",
       "</g>\n",
       "<!-- preprocess -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>preprocess</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"168.9935\" cy=\"-18\" rx=\"62.2891\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.9935\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">preprocess</text>\n",
       "</g>\n",
       "<!-- _start&#45;&gt;preprocess -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>_start&#45;&gt;preprocess</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M69.729,-18C77.9676,-18 87.0729,-18 96.3281,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.3959,-21.5001 106.3959,-18 96.3958,-14.5001 96.3959,-21.5001\"/>\n",
       "</g>\n",
       "<!-- sentiment&#45;analysis -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>sentiment&#45;analysis</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"365.5293\" cy=\"-18\" rx=\"98.2828\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"365.5293\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">sentiment&#45;analysis</text>\n",
       "</g>\n",
       "<!-- preprocess&#45;&gt;sentiment&#45;analysis -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>preprocess&#45;&gt;sentiment&#45;analysis</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M231.4487,-18C239.7785,-18 248.5061,-18 257.3418,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"257.348,-21.5001 267.348,-18 257.348,-14.5001 257.348,-21.5001\"/>\n",
       "</g>\n",
       "<!-- postprocess -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>postprocess</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"566.6146\" cy=\"-18\" rx=\"66.8882\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"566.6146\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">postprocess</text>\n",
       "</g>\n",
       "<!-- sentiment&#45;analysis&#45;&gt;postprocess -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>sentiment&#45;analysis&#45;&gt;postprocess</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M463.7157,-18C472.3627,-18 481.0331,-18 489.4706,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"489.6299,-21.5001 499.6299,-18 489.6299,-14.5001 489.6299,-21.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f1547889490>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the serving graph:\n",
    "graph.to(handler=\"preprocess\", name=\"preprocess\")\\\n",
    "     .to(\"mlrun.frameworks.huggingface.HuggingFaceModelServer\",\n",
    "          name=\"sentiment-analysis\",\n",
    "          task=\"sentiment-analysis\",\n",
    "          model_name=\"distilbert-base-uncased\",\n",
    "          model_class=\"AutoModelForSequenceClassification\",\n",
    "          tokenizer_name=\"distilbert-base-uncased\",\n",
    "          tokenizer_class=\"AutoTokenizer\")\\\n",
    "     .to(handler=\"postprocess\", name=\"postprocess\").respond()\n",
    "\n",
    "# Plot to graph:\n",
    "graph.plot(rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.projects.project.MlrunProject at 0x7f1547cec210>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# registering the serving \n",
    "project.set_function(serving_function)\n",
    "project.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate the application pipeline locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a mocking server for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1015cecce9c4419be86222b91583007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c008710d79429d9c98294201026c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18255cdad6844ac0a3acdc5690297265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe1d68f43ec48169adf38cf3034e7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7028cfbd3bf140c9a3d0cc094bc04df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-10-27 13:21:07,075 [info] model sentiment-analysis was loaded\n"
     ]
    }
   ],
   "source": [
    "server = serving_function.to_mock_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = server.test(path='/predict', body= \"i love flying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The sentiment is POSITIVE', 'The prediction score is 0.5083759427070618']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-10-27 13:21:20,719 [info] Starting remote function deploy\n",
      "2022-10-27 13:21:21  (info) Deploying function\n",
      "2022-10-27 13:21:21  (info) Building\n",
      "2022-10-27 13:21:22  (info) Staging files and preparing base images\n",
      "2022-10-27 13:21:22  (info) Building processor image\n",
      "2022-10-27 13:25:27  (info) Build complete\n",
      "2022-10-27 13:26:25  (info) Function deploy complete\n",
      "> 2022-10-27 13:26:26,065 [info] successfully deployed function: {'internal_invocation_urls': ['nuclio-huggingface-yonatans-hugging-face-serving.default-tenant.svc.cluster.local:8080'], 'external_invocation_urls': ['huggingface-yonatans-hugging-face-serving-huggingface-yonatans.default-tenant.app.yh43.iguazio-cd1.com/']}\n"
     ]
    }
   ],
   "source": [
    "serving_fn = project.deploy_function(serving_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio front-end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradio is a friendly web interface that we demonstrate here how to use easily for submitting predictions to our real-time pipeline and to get the results as well!\n",
    "\n",
    "For more information, please see [gradio page](https://gradio.app/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_url = serving_fn.outputs['endpoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://143f550a53ce1979.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://143f550a53ce1979.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7f146d1b3450>,\n",
       " 'http://127.0.0.1:7860/',\n",
       " 'https://143f550a53ce1979.gradio.app')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentiment(text):\n",
    "    resp = requests.post(serving_url, json={\"text\": text})\n",
    "    return resp.json()\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    input_box = [gr.Textbox(label=\"Text to analyze\", placeholder=\"Please insert text\")]\n",
    "    output = [gr.Textbox(label=\"Sentiment analysis result\"), gr.Textbox(label=\"Sentiment analysis score\")]\n",
    "    greet_btn = gr.Button(\"Submit\")\n",
    "    greet_btn.click(fn=sentiment, inputs=input_box, outputs=output)\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = project.get_function(\"hugging-face-serving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huggingface-yonatans-hugging-face-serving-huggingface-yonatans.default-tenant.app.yh43.iguazio-cd1.com/'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.status.address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://huggingface-yonatans-hugging-face-serving-huggingface-yonatans.default-tenant.app.yh43.iguazio-cd1.com/'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://huggingface-yonatans-hugging-face-serving-huggingface-yonatans.default-tenant.app.yh43.iguazio-cd1.com/'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.spec.command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kind': 'serving',\n",
       " 'metadata': {'name': 'hugging-face-serving',\n",
       "  'tag': '',\n",
       "  'project': 'huggingface-yonatans',\n",
       "  'credentials': {'access_key': '$ref:mlrun-auth-secrets.d12c9fb9d3ba608662ec9b1718c98b10887ea587404f56b2b5f31241'}},\n",
       " 'spec': {'command': 'http://huggingface-yonatans-hugging-face-serving-huggingface-yonatans.default-tenant.app.yh43.iguazio-cd1.com/',\n",
       "  'args': [],\n",
       "  'image': 'yonishelach/ml-models:huggingface-demo-3',\n",
       "  'build': {'functionSourceCode': 'aW1wb3J0IG1scnVuCmZyb20gdHlwaW5nIGltcG9ydCBEaWN0LCBVbmlvbiwgTGlzdAoKTEFCRUxTID0gewogICAgIkxBQkVMXzAiOiAiTkVHQVRJVkUiLAogICAgIkxBQkVMXzEiOiAiUE9TSVRJVkUiCn0KZGVmIHByZXByb2Nlc3ModGV4dDogVW5pb25bc3RyLCBieXRlc10pIC0+IERpY3Q6CiAgICAiIiJDb252ZXJ0aW5nIGEgc2ltcGxlIHRleHQgaW50byBhIHN0cnVjdHVyZWQgYm9keSBmb3IgdGhlIHNlcnZpbmcgZnVuY3Rpb24KICAgIAogICAgOnBhcmFtIHRleHQ6IFRoZSB0ZXh0IHRvIHByZWRpY3QKICAgICIiIgogICAgcmV0dXJuIHsiaW5wdXRzIjogW3N0cih0ZXh0KV19CgoKZGVmIHBvc3Rwcm9jZXNzKG1vZGVsX3Jlc3BvbnNlOiBEaWN0KSAtPiBMaXN0OgogICAgIiIiVHJhbnNmZXJpbmcgdGhlIHByZWRpY3Rpb24gdG8gdGhlIGdyYWRpbyBpbnRlcmZhY2UuCiAgICAKICAgIDpwYXJhbSBtb2RlbF9yZXNwb25zZTogQSBkaWN0IHdpdGggdGhlIG1vZGVsIG91dHB1dAogICAgIiIiCiAgICBvdXRwdXQgPSBtb2RlbF9yZXNwb25zZVsib3V0cHV0cyJdWzBdCiAgICBwcmVkaWN0aW9uID0gTEFCRUxTW291dHB1dFsnbGFiZWwnXV0KICAgIHJldHVybiBbIlRoZSBzZW50aW1lbnQgaXMgIiArIHByZWRpY3Rpb24sICJUaGUgcHJlZGljdGlvbiBzY29yZSBpcyAiICsgc3RyKG91dHB1dFsnc2NvcmUnXSldCgpmcm9tIG1scnVuLnJ1bnRpbWVzIGltcG9ydCBudWNsaW9faW5pdF9ob29rCmRlZiBpbml0X2NvbnRleHQoY29udGV4dCk6CiAgICBudWNsaW9faW5pdF9ob29rKGNvbnRleHQsIGdsb2JhbHMoKSwgJ3NlcnZpbmdfdjInKQoKZGVmIGhhbmRsZXIoY29udGV4dCwgZXZlbnQpOgogICAgcmV0dXJuIGNvbnRleHQubWxydW5faGFuZGxlcihjb250ZXh0LCBldmVudCkK',\n",
       "   'commands': [],\n",
       "   'origin_filename': 'src/gradio_serving.py'},\n",
       "  'description': '',\n",
       "  'default_handler': '',\n",
       "  'disable_auto_mount': True,\n",
       "  'volumes': [],\n",
       "  'volume_mounts': [],\n",
       "  'env': [{'name': 'V3IO_API', 'value': 'v3io-webapi.default-tenant.svc:8081'},\n",
       "   {'name': 'V3IO_USERNAME', 'value': 'yonatans'},\n",
       "   {'name': 'V3IO_FRAMESD', 'value': 'framesd:8081'},\n",
       "   {'name': 'V3IO_ACCESS_KEY',\n",
       "    'valueFrom': {'secretKeyRef': {'key': 'accessKey',\n",
       "      'name': 'mlrun-auth-secrets.d12c9fb9d3ba608662ec9b1718c98b10887ea587404f56b2b5f31241'}}},\n",
       "   {'name': 'MLRUN_AUTH_SESSION',\n",
       "    'valueFrom': {'secretKeyRef': {'key': 'accessKey',\n",
       "      'name': 'mlrun-auth-secrets.d12c9fb9d3ba608662ec9b1718c98b10887ea587404f56b2b5f31241'}}}],\n",
       "  'resources': {'requests': {'memory': '1Mi', 'cpu': '25m'},\n",
       "   'limits': {'memory': '20Gi', 'cpu': '2'}},\n",
       "  'priority_class_name': 'igz-workload-medium',\n",
       "  'preemption_mode': 'prevent',\n",
       "  'min_replicas': 1,\n",
       "  'max_replicas': 4,\n",
       "  'source': '',\n",
       "  'function_kind': 'serving_v2',\n",
       "  'function_handler': 'gradio_serving:handler',\n",
       "  'graph': {'steps': {'preprocess': {'kind': 'task',\n",
       "     'handler': 'preprocess',\n",
       "     'after': []},\n",
       "    'sentiment-analysis': {'kind': 'task',\n",
       "     'class_name': 'mlrun.frameworks.huggingface.HuggingFaceModelServer',\n",
       "     'class_args': {'task': 'sentiment-analysis',\n",
       "      'model_name': 'distilbert-base-uncased',\n",
       "      'model_class': 'AutoModelForSequenceClassification',\n",
       "      'tokenizer_name': 'distilbert-base-uncased',\n",
       "      'tokenizer_class': 'AutoTokenizer'},\n",
       "     'after': ['preprocess']},\n",
       "    'postprocess': {'kind': 'task',\n",
       "     'handler': 'postprocess',\n",
       "     'after': ['sentiment-analysis'],\n",
       "     'responder': True}},\n",
       "   'engine': 'async'},\n",
       "  'secret_sources': [],\n",
       "  'affinity': {'nodeAffinity': {'requiredDuringSchedulingIgnoredDuringExecution': {'nodeSelectorTerms': [{'matchExpressions': [{'key': 'app.iguazio.com/lifecycle',\n",
       "         'operator': 'NotIn',\n",
       "         'values': ['preemptible']},\n",
       "        {'key': 'eks.amazonaws.com/capacityType',\n",
       "         'operator': 'NotIn',\n",
       "         'values': ['SPOT']},\n",
       "        {'key': 'node-lifecycle',\n",
       "         'operator': 'NotIn',\n",
       "         'values': ['spot']}]}]}}},\n",
       "  'tolerations': None,\n",
       "  'security_context': {}},\n",
       " 'status': {'state': 'ready',\n",
       "  'nuclio_name': 'huggingface-yonatans-hugging-face-serving',\n",
       "  'address': 'huggingface-yonatans-hugging-face-serving-huggingface-yonatans.default-tenant.app.yh43.iguazio-cd1.com/',\n",
       "  'internal_invocation_urls': ['nuclio-huggingface-yonatans-hugging-face-serving.default-tenant.svc.cluster.local:8080'],\n",
       "  'external_invocation_urls': ['huggingface-yonatans-hugging-face-serving-huggingface-yonatans.default-tenant.app.yh43.iguazio-cd1.com/']},\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
